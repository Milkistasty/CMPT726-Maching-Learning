\question{Parameter Estimation [35 points]}

In the following parts, consider a random variable $X$ that follows a distribution parameterized by a parameter $\theta$, whose probability density is:

\begin{equation*}
    p(x|\theta) = {\sqrt{\frac{2}{\pi}}}\,{\frac{x^{2}}{\theta^{3}}}\,\exp\!\left({\frac{-x^{2}}{2\theta^{2}}}\right) \qquad \theta > 0, x > 0
\end{equation*}

\textbf{List your collaborators on this question below. }

\begin{solution}

\paragraph{Students I got help from:} WRITE STUDENTS' NAMES HERE

\paragraph{Students I gave help to:} WRITE STUDENTS' NAMES HERE

\paragraph{External sources that I consulted (websites, books, notes, etc.):} LIST ALL EXTERNAL SOURCES HERE

\end{solution}

\qpart{[5 points]}
\textbf{Write down the likelihood function $\mathcal{L}(\theta; \mathcal{D})$ of the parameter $\theta$ given the training data $\mathcal{D} = \left\{x_1, x_2, \ldots, x_N \right\}$, where $x_1, x_2 \ldots, x_N$ are assumed to have been drawn independently of each other from identical distributions.} Show your work. 

\begin{solution}

YOUR SOLUTIONS HERE

{\color{red} Final Conclusion: YOUR FINAL ANSWER OR CONCLUSION HERE}

\end{solution}

\qpart{[5 points]}
\textbf{Write down the log-likelihood function $\log \mathcal{L}(\theta; \mathcal{D})$ of the parameter $\theta$ given the training data $\mathcal{D} = \left\{x_1, x_2, \ldots, x_N \right\}$, where $x_1, x_2 \ldots, x_N$ are assumed to have been drawn independently of each other from identical distributions.} Move the logs in as much as possible and simplify. Show your work. 

\begin{solution}

YOUR SOLUTIONS HERE

{\color{red} Final Conclusion: YOUR FINAL ANSWER OR CONCLUSION HERE}

\end{solution}

\qpart{[5 points]}
\textbf{Derive the expression for critical point(s) of the log-likelihood.} Show your work. 

\begin{solution}

YOUR SOLUTIONS HERE

{\color{red} Final Conclusion: YOUR FINAL ANSWER OR CONCLUSION HERE}

\end{solution}

\qpart{[5 points]}

\textbf{Prove that the critical point found in the previous part is a local maximum. Then using the fact that there is only one critical point, show that the critical point is the global maximum.} Show your work and justify each step that is not a simple algebraic manipulation. 

\begin{solution}

YOUR SOLUTIONS HERE

{\color{red} Final Conclusion: YOUR FINAL ANSWER OR CONCLUSION HERE}

\end{solution}


\qpart{[5 points]}

\textbf{Given a prior over $\theta$, i.e., $\theta \sim \mathcal{N}(0,1)$, write down the objective function for finding the MAP estimate of the parameter $\theta$.} Simplify the objective function to a form that can be differentiated to find the critical point(s) in closed form easily. Justify each step that is not a simple algebraic manipulation. 

\begin{solution}

YOUR SOLUTIONS HERE

{\color{red} Final Conclusion: YOUR FINAL ANSWER OR CONCLUSION HERE}

\end{solution}



\qpart{[5 points]}

\textbf{Differentiate the objective function in the previous part to find the expression for the critical point. Then prove it is a local maximum and a global maximum.} Show your work and justify each step that is not a simple algebraic manipulation.

\begin{solution}

YOUR SOLUTIONS HERE

{\color{red} Final Conclusion: YOUR FINAL ANSWER OR CONCLUSION HERE}

\end{solution}

\qpart{[5 points]}

Consider an arbitrary probability distribution $p(x|\theta)$ parameterized by a scalar parameter $\theta \in [a,b]$. \textbf{Given that the maximum likelihood estimate (MLE) and maximum a posteriori (MAP) estimate of $\theta$ are the same, can you find the prior distribution of $\theta$?} If so, state the name of the distribution and its parameters, and derive it. If not, explain why. 

\begin{solution}

YOUR SOLUTIONS HERE

{\color{red} Final Conclusion: YOUR FINAL ANSWER OR CONCLUSION HERE}

\end{solution}